## Results of Modeling

### Performances of Different Approaches

Using the above methods, we get the following results.

RMSE represents the differences between the predictions and real data. Thus, smaller RMSE indicates that the performance of corresponding model is better. The results in Table @tbl:our-results indicate that Jingzi’s model has the best performance in prediction.

| **Models** | **Features** | **Epochs** | **Hidden Layers** | **Units** | **Learning Rates** | **RMSE** |
|:---------- |:---------:|:-------------:|:-------------:|:-------------:|:----------------:|:--------:|
|Jingzi| 11 | <150* | 5 | 289 | Non-Constant | 227.702 |
| Anye|  12 | 300 | 4 | 131 | Non-Constant | 314.257 |
| Dana | 7 | 800 | 6 | 641 | Constant | 248.733 |
|*Epochs in Jingzi’s model will be stopped when loss reached the minimum. <!-- $colspan="7" --> | | | | | | |
Table: The Average RMSE of Each Models
{#tbl:our-results}

Thus, the sensitivity analysis are based on Jingzi’s model because of its performance in RMSE. 

### Performances of Models with Different Number of Units in Layer 2

In the sensitivity analysis, the number of units in Layer 2 are changed. The performance of models with different number of units in Layer 2 are shown in Table @tbl:units-results .

| **Layer 1** | **Layer 2** | **Layer 3** | **Layer 4** | **Layer 5** | **Learning Rate** | **Normalization** | **Average RMSE** |
|:--------- |:----------:|:---------:|:---------:|:---------:|:-------------:|:------------------:|:------------------:|
| 32 | 16 | 128 | 64 | 1 | Same with Jingzi | At each layer | 246.594 |
| 32 | 32 | 128 | 64 | 1 | Same with Jingzi | At each layer | 241.033 |
| 32 | 64 | 128 | 64 | 1 | Same with Jingzi | At each layer | 232.210 |
| 32 | 128 | 128 | 64 | 1 | Same with Jingzi | At each layer | 243.432 |
Table: The Performance of Models with Different Number of Units in Layer 2
{#tbl:units-results}

Comparing models with different units, the model which has 64 units in Layer 2 had the lowest average RMSE. The results indicate that setting more units in Layer 2 can improve the performance of model in this test dataset. However, the RMSE increase when units in Layer 2 are more than 64.

### Performances of Models with Different Number of Layers

Then, the number of layers are changed to analyze the influence of layers. The performance of models with different number of units in Layer 2 are shown in Table @tbl:layers-results .

| **Layer 1** | **Layer 2** | **Layer 3** | **Layer 4** | **Layer 5** | **Learning Rate** | **Normalization** | **Average RMSE** |
|:--------- |:----------:|:---------:|:---------:|:---------:|:-------------:|:-------------:|:-------------:|
| 32 | 64 | 128 | 64 | 1 | Same with Jingzi | At each layer | 232.210 |
| - | 64 | 128 | 64 | 1 | Same with Jingzi | At each layer | 313.591 |
| - | - | 128 | 64 | 1 | Same with Jingzi | At each layer | 693.552 |
Table: Performances of Models with Different Number of Layers
{#tbl:layers-results}

Comparing models with different number of layers, the model which has 5 layers had the smallest average RMSE. The results indicate that adding more layers properly can improve the performance of model in this test dataset.

### Performances of Models with or without Normalization

Besides, the influence of normalization are analyzed. Normalization in Jingzi’s model was removed. The performance of models with and without normalization are shown in Table @tbl:normalization-results .

| **Layer 1** | **Layer 2** | **Layer 3** | **Layer 4** | **Layer 5** | **Learning Rate** | **Normalization** | **Average RMSE** |
|:--------- |:----------:|:---------:|:---------:|:---------:|:-------------:|:-------------:|:-------------:|:-------------:|
| 32 | 64 | 128 | 64 | 1 | Same with Jingzi | At each layer | 232.210 |
| 32 | 64 | 128 | 64 | 1 | Same with Jingzi | - | 251.478 |
Table: Performances of Models with or without Normalization
{#tbl:normalization-results}

Comparing models with or without normalization, the model which include normalization perform better. The results indicate that normalization can improve the performance of model in this test dataset.

### Performances of Models with Different Learning Rates

Last but not least, learning rates of Jingzi’s training method are changed. The performance of models with different learning rates are shown in Table @tbl:rates-results .

| **Layer 1** | **Layer 2** | **Layer 3** | **Layer 4** | **Layer 5** | **Learning Rate** | **Normalization** | **Average RMSE** | **Epochs** |
|:--------- |:----------:|:---------:|:---------:|:---------:|:------------------:|:------------------:|:------------------:|
| 32 | 64 | 128 | 64 | 1 | Same with Jingzi | At each layer | 232.210 | 119 |
| 32 | 64 | 128 | 64 | 1 | Same with Anye | At each layer | 222.960 | 150 |
| 32 | 64 | 128 | 64 | 1 | 0.001 | At each layer | 223.531 | 150 |
| 32 | 64 | 128 | 64 | 1 | 0.005 | At each layer | 231.112 | 132 |
Table: Performances of Models with Different Learning Rates
{#tbl:rates-results}

Comparing models trained in different learning rates, the methods setting 0.001 as learning rate and setting learning rate scheduler of Anye perform better in RMSE. The methods setting 0.005 as learning rate and setting learning rate scheduler of Jingzi require less epochs. The results indicate that learning rates can influence the performance of model in this test dataset. Moreover, non-constant learning rates or bigger learning rates can shorten the training time in this training dataset. To optimize the initial model, the learning rate scheduler can be changed. The improved smallest RMSE is 210.657 and its average RMSE is 222.960.
